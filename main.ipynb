{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Download the Abalone dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\"\n",
    "response = requests.get(url)\n",
    "with open(\"abalone.data\", \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "    \n",
    "# to read\n",
    "import pandas as pd\n",
    "column_names = ['Sex', 'Length', 'Diameter', 'Height', 'Whole weight', 'Shucked weight', 'Viscera weight', 'Shell weight', 'Rings']\n",
    "data = pd.read_csv(\"abalone.data\", names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (2.1.2)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>1</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>0</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>1</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>0</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Length  Diameter  Height  Whole weight  Shucked weight  \\\n",
       "0       0   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1       0   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2       1   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3       0   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4       2   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...   ...     ...       ...     ...           ...             ...   \n",
       "4172    1   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173    0   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174    0   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175    1   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176    0   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera weight  Shell weight  Rings  \n",
       "0             0.1010        0.1500     15  \n",
       "1             0.0485        0.0700      7  \n",
       "2             0.1415        0.2100      9  \n",
       "3             0.1140        0.1550     10  \n",
       "4             0.0395        0.0550      7  \n",
       "...              ...           ...    ...  \n",
       "4172          0.2390        0.2490     11  \n",
       "4173          0.2145        0.2605     10  \n",
       "4174          0.2875        0.3080      9  \n",
       "4175          0.2610        0.2960     10  \n",
       "4176          0.3765        0.4950     12  \n",
       "\n",
       "[4177 rows x 9 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converter a coluna categorica em numerica\n",
    "# data[\"Sex\"] = data[\"Sex\"].map({\"M\": 0, \"F\": 1, \"I\": 2})\n",
    "\n",
    "data[\"Sex\"] = data[\"Sex\"].map({\"M\": 0, \"F\": 1, \"I\": 2})\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truque de notaÃ§Ã£o, inserindo uma coluna com o valor 1 em todas as linhas\n",
    "\n",
    "data[\"bias\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir entre treino e teste o conjunto de dados\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(\"Rings\", axis=1)\n",
    "\n",
    "y = data[\"Rings\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar a funÃ§Ã£o de custo da regressÃ£o linear\n",
    "\n",
    "def cost_function(X, y, theta):\n",
    "    m = len(y)\n",
    "    J = np.sum((X.dot(theta) - y) ** 2) / (2 * m)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar um vetor de pesos aleatÃ³rios\n",
    "\n",
    "theta = np.random.rand(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IteraÃ§Ã£o 0: Custo = 36.49734405986444\n",
      "IteraÃ§Ã£o 100: Custo = 21.772637169643517\n",
      "IteraÃ§Ã£o 200: Custo = 14.234769845591629\n",
      "IteraÃ§Ã£o 300: Custo = 10.307846700146793\n",
      "IteraÃ§Ã£o 400: Custo = 8.20452871256033\n",
      "IteraÃ§Ã£o 500: Custo = 7.030136821086038\n",
      "IteraÃ§Ã£o 600: Custo = 6.335699366540698\n",
      "IteraÃ§Ã£o 700: Custo = 5.894946482247893\n",
      "IteraÃ§Ã£o 800: Custo = 5.593019746624255\n",
      "IteraÃ§Ã£o 900: Custo = 5.370913808963871\n",
      "IteraÃ§Ã£o 1000: Custo = 5.197724020253989\n",
      "IteraÃ§Ã£o 1100: Custo = 5.056769465408403\n",
      "IteraÃ§Ã£o 1200: Custo = 4.938641920620223\n",
      "IteraÃ§Ã£o 1300: Custo = 4.837713611327019\n",
      "IteraÃ§Ã£o 1400: Custo = 4.750373765458538\n",
      "IteraÃ§Ã£o 1500: Custo = 4.674130526581775\n",
      "IteraÃ§Ã£o 1600: Custo = 4.607147113193203\n",
      "IteraÃ§Ã£o 1700: Custo = 4.547996815722851\n",
      "IteraÃ§Ã£o 1800: Custo = 4.495529069761797\n",
      "IteraÃ§Ã£o 1900: Custo = 4.448792583361664\n",
      "IteraÃ§Ã£o 2000: Custo = 4.406988339829967\n",
      "IteraÃ§Ã£o 2100: Custo = 4.369438719858538\n",
      "IteraÃ§Ã£o 2200: Custo = 4.3355657100634595\n",
      "IteraÃ§Ã£o 2300: Custo = 4.3048745427114685\n",
      "IteraÃ§Ã£o 2400: Custo = 4.276940816930967\n",
      "IteraÃ§Ã£o 2500: Custo = 4.2514000202231434\n",
      "IteraÃ§Ã£o 2600: Custo = 4.2279388175984085\n",
      "IteraÃ§Ã£o 2700: Custo = 4.206287712519225\n",
      "IteraÃ§Ã£o 2800: Custo = 4.18621481326385\n",
      "IteraÃ§Ã£o 2900: Custo = 4.167520512587657\n",
      "IteraÃ§Ã£o 3000: Custo = 4.150032933936451\n",
      "IteraÃ§Ã£o 3100: Custo = 4.13360402726355\n",
      "IteraÃ§Ã£o 3200: Custo = 4.118106218520437\n",
      "IteraÃ§Ã£o 3300: Custo = 4.1034295326638315\n",
      "IteraÃ§Ã£o 3400: Custo = 4.089479122434604\n",
      "IteraÃ§Ã£o 3500: Custo = 4.076173145261137\n",
      "IteraÃ§Ã£o 3600: Custo = 4.063440939032249\n",
      "IteraÃ§Ã£o 3700: Custo = 4.051221454555104\n",
      "IteraÃ§Ã£o 3800: Custo = 4.039461908518492\n",
      "IteraÃ§Ã£o 3900: Custo = 4.028116625906733\n",
      "IteraÃ§Ã£o 4000: Custo = 4.017146045195799\n",
      "IteraÃ§Ã£o 4100: Custo = 4.006515863423775\n",
      "IteraÃ§Ã£o 4200: Custo = 3.996196301454807\n",
      "IteraÃ§Ã£o 4300: Custo = 3.98616147252663\n",
      "IteraÃ§Ã£o 4400: Custo = 3.976388839551726\n",
      "IteraÃ§Ã£o 4500: Custo = 3.9668587486868443\n",
      "IteraÃ§Ã£o 4600: Custo = 3.957554028442261\n",
      "IteraÃ§Ã£o 4700: Custo = 3.948459645111656\n",
      "IteraÃ§Ã£o 4800: Custo = 3.9395624066004795\n",
      "IteraÃ§Ã£o 4900: Custo = 3.9308507078451975\n",
      "IteraÃ§Ã£o 5000: Custo = 3.922314311973522\n",
      "IteraÃ§Ã£o 5100: Custo = 3.9139441621786935\n",
      "IteraÃ§Ã£o 5200: Custo = 3.9057322199880837\n",
      "IteraÃ§Ã£o 5300: Custo = 3.8976713262140628\n",
      "IteraÃ§Ã£o 5400: Custo = 3.889755081397287\n",
      "IteraÃ§Ã£o 5500: Custo = 3.881977743001306\n",
      "IteraÃ§Ã£o 5600: Custo = 3.874334137002989\n",
      "IteraÃ§Ã£o 5700: Custo = 3.86681958185463\n",
      "IteraÃ§Ã£o 5800: Custo = 3.859429823078341\n",
      "IteraÃ§Ã£o 5900: Custo = 3.8521609769980136\n",
      "IteraÃ§Ã£o 6000: Custo = 3.8450094823244183\n",
      "IteraÃ§Ã£o 6100: Custo = 3.837972058489657\n",
      "IteraÃ§Ã£o 6200: Custo = 3.831045669782476\n",
      "IteraÃ§Ã£o 6300: Custo = 3.8242274944693717\n",
      "IteraÃ§Ã£o 6400: Custo = 3.8175148982010305\n",
      "IteraÃ§Ã£o 6500: Custo = 3.810905411102222\n",
      "IteraÃ§Ã£o 6600: Custo = 3.8043967080278946\n",
      "IteraÃ§Ã£o 6700: Custo = 3.7979865915409667\n",
      "IteraÃ§Ã£o 6800: Custo = 3.791672977229862\n",
      "IteraÃ§Ã£o 6900: Custo = 3.785453881037505\n",
      "IteraÃ§Ã£o 7000: Custo = 3.779327408319716\n",
      "IteraÃ§Ã£o 7100: Custo = 3.7732917443905722\n",
      "IteraÃ§Ã£o 7200: Custo = 3.7673451463464063\n",
      "IteraÃ§Ã£o 7300: Custo = 3.7614859359894073\n",
      "IteraÃ§Ã£o 7400: Custo = 3.7557124936969744\n",
      "IteraÃ§Ã£o 7500: Custo = 3.7500232531045734\n",
      "IteraÃ§Ã£o 7600: Custo = 3.7444166964884693\n",
      "IteraÃ§Ã£o 7700: Custo = 3.7388913507506754\n",
      "IteraÃ§Ã£o 7800: Custo = 3.733445783922146\n",
      "IteraÃ§Ã£o 7900: Custo = 3.7280786021121184\n",
      "IteraÃ§Ã£o 8000: Custo = 3.7227884468415438\n",
      "IteraÃ§Ã£o 8100: Custo = 3.717573992707363\n",
      "IteraÃ§Ã£o 8200: Custo = 3.712433945331772\n",
      "IteraÃ§Ã£o 8300: Custo = 3.7073670395571225\n",
      "IteraÃ§Ã£o 8400: Custo = 3.7023720378526126\n",
      "IteraÃ§Ã£o 8500: Custo = 3.697447728903651\n",
      "IteraÃ§Ã£o 8600: Custo = 3.692592926358886\n",
      "IteraÃ§Ã£o 8700: Custo = 3.687806467713395\n",
      "IteraÃ§Ã£o 8800: Custo = 3.68308721330953\n",
      "IteraÃ§Ã£o 8900: Custo = 3.67843404543953\n",
      "IteraÃ§Ã£o 9000: Custo = 3.6738458675362047\n",
      "IteraÃ§Ã£o 9100: Custo = 3.669321603439953\n",
      "IteraÃ§Ã£o 9200: Custo = 3.664860196731964\n",
      "IteraÃ§Ã£o 9300: Custo = 3.6604606101249333\n",
      "IteraÃ§Ã£o 9400: Custo = 3.6561218249037646\n",
      "IteraÃ§Ã£o 9500: Custo = 3.6518428404098495\n",
      "IteraÃ§Ã£o 9600: Custo = 3.6476226735633417\n",
      "IteraÃ§Ã£o 9700: Custo = 3.643460358418668\n",
      "IteraÃ§Ã£o 9800: Custo = 3.6393549457491576\n",
      "IteraÃ§Ã£o 9900: Custo = 3.6353055026572356\n"
     ]
    }
   ],
   "source": [
    "# NÃºmero de iteraÃ§Ãµes\n",
    "num_iterations = 10000\n",
    "\n",
    "    # Defina uma taxa de aprendizado\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Loop de treinamento\n",
    "for i in range(num_iterations):\n",
    "\n",
    "    # Calcule a previsÃ£o do modelo\n",
    "    predictions = X_train.dot(theta)\n",
    "    # Calcule o erro\n",
    "    error = predictions - y_train\n",
    "    # Calcule o gradiente\n",
    "    gradient = X_train.T.dot(error) / len(y_train)\n",
    "    # Atualize os pesos\n",
    "    theta = theta - learning_rate * gradient\n",
    "\n",
    "    # A cada 100 iteraÃ§Ãµes, exibir o custo para monitoramento\n",
    "    if i % 100 == 0:\n",
    "        J = cost_function(X_train, y_train, theta)\n",
    "        print(f\"IteraÃ§Ã£o {i}: Custo = {J}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 7.327393692300634\n",
      "R2 Score: 0.32311764284817357\n",
      "Mean Absolute Error: 1.9524967031206255\n"
     ]
    }
   ],
   "source": [
    "# obtenha as mÃ©tricas do modelo gerado\n",
    "\n",
    "predictions = X_test.dot(theta)\n",
    "\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, predictions))\n",
    "\n",
    "print(\"R2 Score:\", r2_score(y_test, predictions))\n",
    "\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 4.950310502936191\n",
      "R2 Score: 0.5427053625654411\n",
      "Mean Absolute Error: 1.6067608598250254\n"
     ]
    }
   ],
   "source": [
    "# compare com o modelo do sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_test, predictions))\n",
    "print(\"R2 Score:\", r2_score(y_test, predictions))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
